import subprocess
import urllib.parse
import csv

# Grafana API details
GRAFANA_URL = "https://us.aether.nss.vzwnet.com/gem/prometheus/api/v1/query_range"

# Load API keys from a text file
def load_api_keys(file_path):
    api_keys = {}
    with open(file_path, "r") as file:
        for line in file:
            function, api_key = line.strip().split(":")
            api_keys[function.strip()] = api_key.strip()
    return api_keys

# Load metrics from a text file
def load_metrics(file_path):
    with open(file_path, "r") as file:
        return [line.strip() for line in file if line.strip()]

# Build the cURL command properly
def build_curl_command(api_key, query, start_epoch, end_epoch):
    encoded_query = urllib.parse.quote(query)
    curl_command = (
        f"curl --location --globoff '{GRAFANA_URL}?query={encoded_query}&start={start_epoch}&end={end_epoch}&step=60m' "
        f"--header 'Authorization: Bearer {api_key}'"
    )
    return curl_command

# Execute cURL command and get response
def execute_curl_and_get_data(curl_command):
    try:
        result = subprocess.run(
            curl_command,
            shell=True,
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
        )
        return result.stdout.decode("utf-8")
    except subprocess.CalledProcessError as e:
        print(f"Error executing cURL command: {e.stderr.decode('utf-8')}")
        return None

# Save results to CSV
def save_to_csv(data, output_file):
    keys = ["event_time", "fqdn", "metric_name", "metric_sum", "metric_increase"]
    with open(output_file, "w", newline="") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=keys)
        writer.writeheader()
        writer.writerows(data)

# Main function
def main():
    # File paths for API keys and metrics
    api_keys_file = "api_keys.txt"
    amf_metrics_file = "amf_metrics.txt"
    smf_metrics_file = "smf_metrics.txt"
    upf_metrics_file = "upf_metrics.txt"

    # Load API keys and metrics
    api_keys = load_api_keys(api_keys_file)
    amf_metrics = load_metrics(amf_metrics_file)
    smf_metrics = load_metrics(smf_metrics_file)
    upf_metrics = load_metrics(upf_metrics_file)

    # Define start and end times (Epoch format)
    start_epoch = "1717632000"  # Replace with actual start time
    end_epoch = "1733356800"    # Replace with actual end time

    # Initialize results
    results = []

    # Process AMF metrics
    if "amf" in api_keys:
        print("Processing AMF metrics...")
        for metric in amf_metrics:
            query = f"sum by (kubernetes_namespace) (sum_over_time({metric}[1h]))"
            curl_command = build_curl_command(api_keys["amf"], query, start_epoch, end_epoch)
            print(f"Executing cURL: {curl_command}")
            response = execute_curl_and_get_data(curl_command)
            if response:
                print(f"Fetched data for metric: {metric}")
                # TODO: Parse the response JSON and add the data to `results`
    else:
        print("No API key found for AMF. Skipping...")

    # Process SMF metrics
    if "smf" in api_keys:
        print("Processing SMF metrics...")
        for metric in smf_metrics:
            query = f"sum by (kubernetes_namespace) (sum_over_time({metric}[1h]))"
            curl_command = build_curl_command(api_keys["smf"], query, start_epoch, end_epoch)
            print(f"Executing cURL: {curl_command}")
            response = execute_curl_and_get_data(curl_command)
            if response:
                print(f"Fetched data for metric: {metric}")
                # TODO: Parse the response JSON and add the data to `results`
    else:
        print("No API key found for SMF. Skipping...")

    # Process UPF metrics
    if "upf" in api_keys:
        print("Processing UPF metrics...")
        for metric in upf_metrics:
            query = f"sum by (local_dn) (sum_over_time({metric}[1h]))"
            curl_command = build_curl_command(api_keys["upf"], query, start_epoch, end_epoch)
            print(f"Executing cURL: {curl_command}")
            response = execute_curl_and_get_data(curl_command)
            if response:
                print(f"Fetched data for metric: {metric}")
                # TODO: Parse the response JSON and add the data to `results`
    else:
        print("No API key found for UPF. Skipping...")

    # Save all results to CSV
    if results:
        save_to_csv(results, "grafana_metrics.csv")
        print("Results saved to grafana_metrics.csv")
    else:
        print("No data fetched.")

if __name__ == "__main__":
    main()
